{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn import cluster\n",
    "import scipy\n",
    "from scipy.linalg import eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova de Algebra Linear \n",
    "\n",
    "### Dataset escolhido: twitter-airline-sentiment disponivel no Kaggle\n",
    "https://www.kaggle.com/crowdflower/twitter-airline-sentiment#Tweets.csv\n",
    "\n",
    "O dataset foi escolhido pois ele possui texto e classificação quanto ao sentimento de cada tweet. O objetivo aqui será tentar aplicar as técnicas de Spectral Clustering para agrupar corretamente os tweets de acordo com seu conteúdo semântico\n",
    "\n",
    "Esse notebook apresenta os resultados obtidos utilizando extração de atributos com a tecnica Tf-Idf, onde cada atributo representa a frequência de ocorrência de palavras em cada documento. As configurações de hiperparâmetros dos três métodos de Spectral Clustering foram testadas exaustivamente e os melhores resultados são apresentados e comparandos com a técnica mais básica de clustering, o kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./twitter-airline-sentiment/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colunas de interesse: id, sentimento (label) e o texto em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  \\\n",
       "0  570306133677760513           neutral   \n",
       "1  570301130888122368          positive   \n",
       "2  570301083672813571           neutral   \n",
       "3  570301031407624196          negative   \n",
       "4  570300817074462722          negative   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = df[['tweet_id', 'airline_sentiment', 'text']]\n",
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  airline_sentiment  \\\n",
       "0  570306133677760513                  1   \n",
       "1  570301130888122368                  2   \n",
       "2  570301083672813571                  1   \n",
       "3  570301031407624196                  0   \n",
       "4  570300817074462722                  0   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['airline_sentiment'] = train_ds['airline_sentiment'].map({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o sklearn para extrair features do texto.\n",
    "\n",
    "A maneira mais simples de fazer isso é utilizar a contagem de frequência de palavras no texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14640x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 222797 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "feature_vector = count_vectorizer.fit(train_ds.text)\n",
    "train_ds_features = count_vectorizer.transform(train_ds.text)\n",
    "\n",
    "train_ds_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coincidence',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'colleague',\n",
       " 'colleagues',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'color',\n",
       " 'columbia',\n",
       " 'columbus',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'comcast',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'comm',\n",
       " 'comment',\n",
       " 'comments',\n",
       " 'commercial',\n",
       " 'commercials',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'communicated',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'companies',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'compassion',\n",
       " 'comped',\n",
       " 'compensate',\n",
       " 'compensated',\n",
       " 'compensation',\n",
       " 'competent',\n",
       " 'competition',\n",
       " 'competitor',\n",
       " 'complain',\n",
       " 'complained',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complicated',\n",
       " 'compliment',\n",
       " 'complimentary',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerns',\n",
       " 'concert',\n",
       " 'concourse',\n",
       " 'condition',\n",
       " 'conditions',\n",
       " 'conf',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'confirmed',\n",
       " 'confirming',\n",
       " 'conflicting',\n",
       " 'confused',\n",
       " 'confusing',\n",
       " 'confusion',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connecting',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'connector',\n",
       " 'consecutive',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'consumers',\n",
       " 'cont',\n",
       " 'contact',\n",
       " 'contacted',\n",
       " 'contacting',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'continental',\n",
       " 'contingency',\n",
       " 'continually',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'continuous',\n",
       " 'contract',\n",
       " 'control',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'convo',\n",
       " 'cookies',\n",
       " 'cool',\n",
       " 'coordinate',\n",
       " 'copy',\n",
       " 'corp',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'corrected',\n",
       " 'correctly',\n",
       " 'cost',\n",
       " 'costa',\n",
       " 'costing',\n",
       " 'costs',\n",
       " 'costumer',\n",
       " 'cot',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'coupon',\n",
       " 'coupons',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courteous',\n",
       " 'courtesy',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'cowboycerrone',\n",
       " 'coworker',\n",
       " 'coworkers',\n",
       " 'cp',\n",
       " 'cr',\n",
       " 'crackers',\n",
       " 'cramped',\n",
       " 'cranky',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'crash',\n",
       " 'crashed',\n",
       " 'crashing',\n",
       " 'craziness',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'credit',\n",
       " 'credited',\n",
       " 'credits',\n",
       " 'crew',\n",
       " 'crewmember',\n",
       " 'crewmembers',\n",
       " 'crews',\n",
       " 'crisis',\n",
       " 'cross',\n",
       " 'crossed',\n",
       " 'crowd',\n",
       " 'crowded',\n",
       " 'cruel',\n",
       " 'cruise',\n",
       " 'cry',\n",
       " 'crying',\n",
       " 'cs',\n",
       " 'csr',\n",
       " 'ct',\n",
       " 'ctl',\n",
       " 'cuba',\n",
       " 'cue',\n",
       " 'culture',\n",
       " 'cun',\n",
       " 'cup',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cust',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'customerservice',\n",
       " 'customerservicefail',\n",
       " 'customs',\n",
       " 'custserv',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutting',\n",
       " 'cuz',\n",
       " 'cvg',\n",
       " 'cx',\n",
       " 'cxl',\n",
       " 'cxld',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'dal',\n",
       " 'dallas',\n",
       " 'dallaslovefield',\n",
       " 'damage',\n",
       " 'damaged',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dang',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darn',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dates',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'david',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'days',\n",
       " 'daytona',\n",
       " 'dc',\n",
       " 'dca',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deadhead',\n",
       " 'deaf',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'deals',\n",
       " 'dealt',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debacle',\n",
       " 'december',\n",
       " 'decency',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'deck',\n",
       " 'deep',\n",
       " 'def',\n",
       " 'define',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'degrees',\n",
       " 'deicing',\n",
       " 'del',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delaying',\n",
       " 'delays',\n",
       " 'delete',\n",
       " 'deleted',\n",
       " 'delhi',\n",
       " 'deliver',\n",
       " 'delivered',\n",
       " 'delivery',\n",
       " 'delta',\n",
       " 'deltaassist',\n",
       " 'den',\n",
       " 'denied',\n",
       " 'denver',\n",
       " 'deny',\n",
       " 'dep',\n",
       " 'depart',\n",
       " 'departed',\n",
       " 'departing',\n",
       " 'department',\n",
       " 'departs',\n",
       " 'departure',\n",
       " 'departures',\n",
       " 'deplane',\n",
       " 'deplaned',\n",
       " 'deplaning',\n",
       " 'deplorable',\n",
       " 'dept',\n",
       " 'derekc21',\n",
       " 'derrick',\n",
       " 'describe',\n",
       " 'deserve',\n",
       " 'deserved',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'desk',\n",
       " 'desks',\n",
       " 'desktop',\n",
       " 'desperately',\n",
       " 'despite',\n",
       " 'dest',\n",
       " 'destination',\n",
       " 'destinationdragons',\n",
       " 'destinations',\n",
       " 'destroyed',\n",
       " 'detail',\n",
       " 'detailed',\n",
       " 'details',\n",
       " 'detroit',\n",
       " 'develop',\n",
       " 'device',\n",
       " 'devices',\n",
       " 'dfw',\n",
       " 'dfwairport',\n",
       " 'dia',\n",
       " 'dial',\n",
       " 'dialing',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'died',\n",
       " 'diego',\n",
       " 'diff',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'difficulties',\n",
       " 'digital',\n",
       " 'dime',\n",
       " 'dining',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'directly',\n",
       " 'directtv',\n",
       " 'dirty',\n",
       " 'disabled',\n",
       " 'disappear',\n",
       " 'disappeared',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'disaster',\n",
       " 'disconnect',\n",
       " 'disconnected',\n",
       " 'disconnects',\n",
       " 'discount',\n",
       " 'discounts',\n",
       " 'discover',\n",
       " 'discovered',\n",
       " 'discrimination',\n",
       " 'discuss',\n",
       " 'disgrace',\n",
       " 'disgraceful',\n",
       " 'disgruntled',\n",
       " 'disgusted',\n",
       " 'disgusting',\n",
       " 'dislike',\n",
       " 'disney',\n",
       " 'disorganization',\n",
       " 'disorganized',\n",
       " 'display',\n",
       " 'displayed',\n",
       " 'disregard',\n",
       " 'disrespect',\n",
       " 'disrespectful',\n",
       " 'dissatisfied',\n",
       " 'distribution',\n",
       " 'div',\n",
       " 'diversion',\n",
       " 'divert',\n",
       " 'diverted',\n",
       " 'diverting',\n",
       " 'dividend',\n",
       " 'dividends',\n",
       " 'dl',\n",
       " 'dm',\n",
       " 'dmed',\n",
       " 'dming',\n",
       " 'dms',\n",
       " 'do',\n",
       " 'dobetter',\n",
       " 'document',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'doing',\n",
       " 'dollar',\n",
       " 'dollars',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'donate',\n",
       " 'donation',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'doug',\n",
       " 'down',\n",
       " 'downgrade',\n",
       " 'downhill',\n",
       " 'download',\n",
       " 'downtown',\n",
       " 'dozen',\n",
       " 'dozens',\n",
       " 'dpt',\n",
       " 'dr',\n",
       " 'dragon',\n",
       " 'dragons',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'drink',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'dropping',\n",
       " 'drops',\n",
       " 'drove',\n",
       " 'drunk',\n",
       " 'drunks',\n",
       " 'dry',\n",
       " 'dsm',\n",
       " 'dtw',\n",
       " 'dub',\n",
       " 'dublin',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'duffle',\n",
       " 'duh',\n",
       " 'dulles',\n",
       " 'dulles_airport',\n",
       " 'dumb',\n",
       " 'dunno',\n",
       " 'durango',\n",
       " 'during',\n",
       " 'duty',\n",
       " 'dying',\n",
       " 'e190',\n",
       " 'each',\n",
       " 'eagle',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earn',\n",
       " 'earned',\n",
       " 'earth',\n",
       " 'easier',\n",
       " 'easiest',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eco',\n",
       " 'econ',\n",
       " 'economy',\n",
       " 'ed',\n",
       " 'educate',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'efforts',\n",
       " 'either',\n",
       " 'el',\n",
       " 'elderly',\n",
       " 'elevate',\n",
       " 'elite',\n",
       " 'ella',\n",
       " 'ellahenderson',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'em',\n",
       " 'email',\n",
       " 'emailed',\n",
       " 'emailing',\n",
       " 'emails',\n",
       " 'embarrassed',\n",
       " 'embarrassing',\n",
       " 'embossed',\n",
       " 'embraersa',\n",
       " 'emerald',\n",
       " 'emergency',\n",
       " 'emp',\n",
       " 'empathy',\n",
       " 'employ',\n",
       " 'employee',\n",
       " 'employees',\n",
       " 'employer',\n",
       " 'empty',\n",
       " 'ems',\n",
       " 'emv',\n",
       " 'en',\n",
       " 'encountered',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'endless',\n",
       " 'endlessly',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'enforcing',\n",
       " 'engaging',\n",
       " 'engine',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enough',\n",
       " 'enquires',\n",
       " 'enroll',\n",
       " 'enroute',\n",
       " 'ensure',\n",
       " 'ensuring',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'entering',\n",
       " 'enterprise',\n",
       " 'entertain',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'entitled',\n",
       " 'entrance',\n",
       " 'entry',\n",
       " 'enuf',\n",
       " 'environment',\n",
       " 'envoy',\n",
       " 'ep',\n",
       " 'epic',\n",
       " 'epicfail',\n",
       " 'epicfailunited',\n",
       " 'equal',\n",
       " 'equally',\n",
       " 'equip',\n",
       " 'equipment',\n",
       " 'eri',\n",
       " 'erj145',\n",
       " 'err',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'ers',\n",
       " 'es',\n",
       " 'escape',\n",
       " 'esp',\n",
       " 'especially',\n",
       " 'espinosa',\n",
       " 'essentially',\n",
       " 'est',\n",
       " 'establish',\n",
       " 'established',\n",
       " 'estimate',\n",
       " 'estimated',\n",
       " 'eta',\n",
       " 'etc',\n",
       " 'etfjqiwuvt',\n",
       " 'ethiopia',\n",
       " 'etihad',\n",
       " 'eu',\n",
       " 'europe',\n",
       " 'evaluate',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'evenlate',\n",
       " 'event',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everytime',\n",
       " 'everywhere',\n",
       " 'evoucher',\n",
       " 'evry',\n",
       " 'ewr',\n",
       " 'ex',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'exceed',\n",
       " 'excellence',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exception',\n",
       " 'exceptional',\n",
       " 'exceptions',\n",
       " 'exchange',\n",
       " 'excited',\n",
       " 'exclusively',\n",
       " 'excuse',\n",
       " 'excuses',\n",
       " 'exec',\n",
       " 'execplat',\n",
       " 'execution',\n",
       " 'executive',\n",
       " 'exercise',\n",
       " 'exhausted',\n",
       " 'exist',\n",
       " 'existence',\n",
       " 'existent',\n",
       " 'existing',\n",
       " 'exists',\n",
       " 'exit',\n",
       " 'exp',\n",
       " 'expanding',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expedia',\n",
       " 'expedient',\n",
       " 'expedite',\n",
       " 'expedited',\n",
       " 'expense',\n",
       " 'expenses',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiences',\n",
       " 'experiencing',\n",
       " 'expiration',\n",
       " 'expire',\n",
       " 'expired',\n",
       " 'expires',\n",
       " 'expiring',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'explains',\n",
       " 'explanation',\n",
       " 'explanations',\n",
       " 'explore',\n",
       " 'explorer',\n",
       " 'express',\n",
       " 'extend',\n",
       " 'extended',\n",
       " 'extension',\n",
       " 'extra',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'ey',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'eyw',\n",
       " 'f2lfulcbq7',\n",
       " 'fa',\n",
       " 'faa',\n",
       " 'faanews',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'faces',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fails',\n",
       " 'failure',\n",
       " 'failures',\n",
       " 'fair',\n",
       " 'fairs',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'fallow',\n",
       " 'falls',\n",
       " 'false',\n",
       " 'fam',\n",
       " 'families',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fare',\n",
       " 'farecompare',\n",
       " 'fares',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fastest',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fault',\n",
       " 'faulty',\n",
       " 'fav',\n",
       " 'fave',\n",
       " 'favor',\n",
       " 'favorite',\n",
       " 'fb',\n",
       " 'fc',\n",
       " 'fear',\n",
       " 'feature',\n",
       " 'feb',\n",
       " 'february',\n",
       " 'fed',\n",
       " 'federal',\n",
       " 'fee',\n",
       " 'feed',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'fees',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fella',\n",
       " 'felt',\n",
       " 'ferry',\n",
       " 'few',\n",
       " 'fewer',\n",
       " 'ff',\n",
       " 'ffl',\n",
       " 'fi',\n",
       " 'fiancé',\n",
       " 'fiasco',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'figure',\n",
       " 'figured',\n",
       " 'file',\n",
       " 'filed',\n",
       " 'filing',\n",
       " 'fill',\n",
       " 'filled',\n",
       " 'filling',\n",
       " 'film',\n",
       " 'filmcrew',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'finals',\n",
       " 'financial',\n",
       " 'find',\n",
       " 'finder',\n",
       " 'finding',\n",
       " 'finds',\n",
       " 'fine',\n",
       " 'finest',\n",
       " 'finger',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'finnair',\n",
       " 'fioretti2ndward',\n",
       " 'fire',\n",
       " 'fired',\n",
       " 'firefox',\n",
       " 'first',\n",
       " 'firstclass',\n",
       " 'firstworldproblems',\n",
       " 'fit',\n",
       " 'fits',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'fixing',\n",
       " 'fl',\n",
       " 'flashlight',\n",
       " 'flat',\n",
       " 'flattering',\n",
       " 'flaw',\n",
       " 'flawed',\n",
       " 'fleek',\n",
       " 'fleet',\n",
       " 'flew',\n",
       " 'flex',\n",
       " 'flexibility',\n",
       " 'flexible',\n",
       " 'flght',\n",
       " 'flgt',\n",
       " 'flier',\n",
       " 'flierfriendly',\n",
       " 'fliers',\n",
       " 'flies',\n",
       " 'flight',\n",
       " 'flight293',\n",
       " 'flightation',\n",
       " 'flightations',\n",
       " 'flightaware',\n",
       " 'flightd',\n",
       " 'flighted',\n",
       " 'flightedflight',\n",
       " 'flightfail',\n",
       " 'flighting',\n",
       " 'flightlation',\n",
       " 'flightlations',\n",
       " 'flightled',\n",
       " 'flightledflight',\n",
       " 'flightling',\n",
       " 'flightly',\n",
       " 'flightr',\n",
       " 'flights',\n",
       " 'flightst',\n",
       " 'fll',\n",
       " 'floor',\n",
       " 'florida',\n",
       " 'flown',\n",
       " 'flt',\n",
       " 'flts',\n",
       " 'fly',\n",
       " 'fly2ohare',\n",
       " 'fly_nashville',\n",
       " 'flydelta',\n",
       " 'flyer',\n",
       " 'flyers',\n",
       " 'flyfi',\n",
       " 'flying',\n",
       " 'flyingitforward',\n",
       " 'flyitforward',\n",
       " 'flylaxairport',\n",
       " 'flysfo',\n",
       " 'flysouthwest',\n",
       " 'flytpa',\n",
       " 'flyunited',\n",
       " 'folder',\n",
       " 'folk',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'force',\n",
       " 'forced',\n",
       " 'forces',\n",
       " 'forcing',\n",
       " 'forecast',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgetting',\n",
       " 'forgive',\n",
       " 'forgot',\n",
       " 'forgotten',\n",
       " 'form',\n",
       " 'formal',\n",
       " 'formally',\n",
       " 'former',\n",
       " 'forms',\n",
       " 'fort',\n",
       " 'forth',\n",
       " 'fortunately',\n",
       " 'fortunemagazine',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'foxnews',\n",
       " 'fr',\n",
       " 'fra',\n",
       " 'fran',\n",
       " 'france',\n",
       " 'franchise02',\n",
       " 'francisco',\n",
       " 'frank',\n",
       " 'frankfurt',\n",
       " 'frankly',\n",
       " 'fraud',\n",
       " 'freaked',\n",
       " 'freaking',\n",
       " 'free',\n",
       " 'freezing',\n",
       " 'french',\n",
       " 'freq',\n",
       " 'frequency',\n",
       " 'frequent',\n",
       " 'frequentflyer',\n",
       " 'fresh',\n",
       " 'fresno',\n",
       " 'freyabevan_fund',\n",
       " 'freyasfund',\n",
       " 'fri',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friendliest',\n",
       " 'friendly',\n",
       " 'friendlyskies',\n",
       " 'friends',\n",
       " 'frigid',\n",
       " 'frm',\n",
       " 'from',\n",
       " 'front',\n",
       " 'frontier',\n",
       " 'frontrunner',\n",
       " 'frozen',\n",
       " 'frustrated',\n",
       " 'frustrating',\n",
       " 'frustration',\n",
       " 'frustrations',\n",
       " 'ft',\n",
       " 'ftw',\n",
       " 'fuck',\n",
       " 'fucked',\n",
       " 'fucken',\n",
       " 'fucking',\n",
       " 'fuel',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'functionality',\n",
       " 'functioning',\n",
       " 'funds',\n",
       " 'funeral',\n",
       " 'funny',\n",
       " 'furious',\n",
       " 'furrow',\n",
       " 'further',\n",
       " 'future',\n",
       " 'fyi',\n",
       " 'gain',\n",
       " 'gainesville',\n",
       " 'galley',\n",
       " 'game',\n",
       " 'garbage',\n",
       " 'gary',\n",
       " 'gas',\n",
       " 'gate',\n",
       " 'gates',\n",
       " 'gave',\n",
       " 'gear',\n",
       " 'gee',\n",
       " 'geeks',\n",
       " 'general',\n",
       " 'generic',\n",
       " 'george',\n",
       " 'gesture',\n",
       " 'get',\n",
       " 'getaway',\n",
       " 'getittogether',\n",
       " 'gets',\n",
       " 'gettin',\n",
       " 'getting',\n",
       " 'gf',\n",
       " 'gfc',\n",
       " 'gg8929',\n",
       " 'ggreenwald',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'gifts',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'gj',\n",
       " 'glad',\n",
       " 'gladly',\n",
       " 'glasgow',\n",
       " 'glass',\n",
       " 'glasses',\n",
       " 'glitch',\n",
       " 'glitches',\n",
       " 'global',\n",
       " 'globe',\n",
       " 'gloves',\n",
       " 'gluten',\n",
       " 'gma',\n",
       " 'gmail',\n",
       " 'gng',\n",
       " 'gnv',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'gogh',\n",
       " 'gogo',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'goingforgreat',\n",
       " 'goingforgreatnessfail',\n",
       " 'gold',\n",
       " 'golf',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'goodcustomerservice']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = feature_vector.get_feature_names()\n",
    "features[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00pm</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features  counts\n",
       "0       00      14\n",
       "1      000      31\n",
       "2     0016       3\n",
       "3     00pm       5\n",
       "4       02       6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_counts = np.sum( train_ds_features.toarray(), axis = 0 )\n",
    "feature_counts = pd.DataFrame( dict( features = features,\n",
    "                                  counts = features_counts ) )\n",
    "\n",
    "feature_counts.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>united</td>\n",
       "      <td>4164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>flight</td>\n",
       "      <td>3939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>usairways</td>\n",
       "      <td>3053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>americanair</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>southwestair</td>\n",
       "      <td>2461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>jetblue</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>http</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4472</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>cancelled</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>just</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>service</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>help</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>time</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>customer</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>amp</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>hours</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>flights</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>hold</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>plane</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>thank</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          features  counts\n",
       "4708        united    4164\n",
       "1919        flight    3939\n",
       "4746     usairways    3053\n",
       "493    americanair    2964\n",
       "4230  southwestair    2461\n",
       "2617       jetblue    2395\n",
       "2425          http    1155\n",
       "4472        thanks    1083\n",
       "996      cancelled    1065\n",
       "2646          just     974\n",
       "4088       service     967\n",
       "2327          help     873\n",
       "4528          time     793\n",
       "1369      customer     758\n",
       "498            amp     683\n",
       "2416         hours     674\n",
       "1936       flights     649\n",
       "2359          hold     644\n",
       "3419         plane     638\n",
       "4468         thank     605"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer( stop_words = \"english\",\n",
    "                                 max_features = 5000 )\n",
    "feature_vector = count_vectorizer.fit( train_ds.text )\n",
    "train_ds_features = count_vectorizer.transform( train_ds.text )\n",
    "\n",
    "features = feature_vector.get_feature_names()\n",
    "features_counts = np.sum( train_ds_features.toarray(), axis = 0 )\n",
    "feature_counts = pd.DataFrame( dict( features = features,\n",
    "                                  counts = features_counts ) )\n",
    "feature_counts.sort_values( \"counts\", ascending = False )[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14640x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 122964 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tf_idf_vector = transformer.fit(train_ds_features)\n",
    "tf_idf_features = transformer.fit_transform(train_ds_features)\n",
    "tf_idf_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas\n",
    "\n",
    "Vamos utilizar como metricas do clustering: homogeinity e completeness\n",
    "\n",
    "Vamos comparar os resultados do spectral clustering com os resultados obtidos utilizando o kmeans++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.016127271008612595 \n",
      "Homogeinity: 0.01676096076673386\n"
     ]
    }
   ],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "k_means_preds = kmeans.fit_predict(tf_idf_features)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=k_means_preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=k_means_preds)\n",
    "print(\"Completeness: {} \\nHomogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de spectral clustering\n",
    "\n",
    "Na célula abaixamos implementamos os três diferentes métodos propostos no artigo.\n",
    "\n",
    "A seguir vamos construir os grafos de similaridade e testar cada um dos métodos, variando o tipo de grafo e o tipo de função de similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalized_spectral_clustering(similarity_matrix, num_clusters):\n",
    "    G = nx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    laplacian = nx.laplacian_matrix(G)\n",
    "    eigvals, eigvecs = scipy.sparse.linalg.eigs(laplacian.toarray(), k=num_clusters, which='SM')\n",
    "    eigvecs = np.real_if_close(eigvecs)\n",
    "    kmeans = cluster.KMeans(n_clusters=num_clusters)\n",
    "    preds = kmeans.fit_predict(eigvecs)\n",
    "    return preds\n",
    "\n",
    "def shi_spectral_clustering(similarity_matrix, num_clusters):\n",
    "    G = nx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    laplacian = nx.laplacian_matrix(G)\n",
    "    n, m = similarity_matrix.shape\n",
    "    diags = similarity_matrix.sum(axis=1)\n",
    "    D = scipy.sparse.spdiags(diags.flatten(), [0], m, n, format='csr')\n",
    "    eigvals, eigvecs = scipy.sparse.linalg.eigs(laplacian.toarray(), k=num_clusters, which='SM', M=D)\n",
    "    eigvecs = np.real_if_close(eigvecs)\n",
    "    kmeans = cluster.KMeans(n_clusters=num_clusters)\n",
    "    preds = kmeans.fit_predict(eigvecs)\n",
    "    return preds\n",
    "\n",
    "def ng_spectral_clustering(similarity_matrix, num_clusters):\n",
    "    G = nx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    laplacian = nx.normalized_laplacian_matrix(G)\n",
    "    n, m = similarity_matrix.shape\n",
    "    diags = similarity_matrix.sum(axis=1)\n",
    "    D = scipy.sparse.spdiags(diags.flatten(), [0], m, n, format='csr')\n",
    "    eigvals, eigvecs = scipy.sparse.linalg.eigs(laplacian.toarray(), k=num_clusters, which='SM', M=D)\n",
    "    eigvecs = np.real_if_close(eigvecs)\n",
    "    T = eigvecs / np.linalg.norm(eigvecs, axis=1)[:, np.newaxis]\n",
    "    kmeans = cluster.KMeans(n_clusters=num_clusters)\n",
    "    preds = kmeans.fit_predict(eigvecs)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo de similaridade\n",
    "\n",
    "Primeiro, tentamos com a distancia euclidiana, por simplicidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN graph\n",
    "\n",
    "Os autores sugerem que o numero de vizinhos deve ser suficientemente grande para que tenhamos um grafo conexo\n",
    "\n",
    "Vale ressaltar que para valores pequenos no numero de vizinhos as matrizes D ficaram mal-condicionadas, tornando o problema de encontrar os autovetores generalizados inviavel\n",
    "\n",
    "Diversos valores foram testados para gerar o knn_graph, verificou-se que para os dois primeiros algoritmos, um numero maior de vizinhos teve um resultado melhor, enquanto que para o terceiro algoritmo n=50 foi o que teve o melhor resultado. Note que ele foi o maior dentre os tres, utilizando a distancia euclidiana como metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14640]\n"
     ]
    }
   ],
   "source": [
    "knn_graph = kneighbors_graph(tf_idf_features, n_neighbors=200, mode='distance', include_self=True)\n",
    "G = nx.from_scipy_sparse_matrix(knn_graph)\n",
    "print([len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.18775390710410184 \n",
      " Homogeinity: 0.1296837698851961\n"
     ]
    }
   ],
   "source": [
    "preds = unnormalized_spectral_clustering(similarity_matrix=knn_graph, num_clusters=3)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "print(\"Completeness: {} \\n Homogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shi Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.1819380134580632 \n",
      " Homogeinity: 0.13504716013787285\n"
     ]
    }
   ],
   "source": [
    "preds = shi_spectral_clustering(similarity_matrix=knn_graph, num_clusters=3)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "print(\"Completeness: {} \\n Homogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ng Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.17662664761262414 \n",
      " Homogeinity: 0.1342070759529893\n"
     ]
    }
   ],
   "source": [
    "knn_graph = kneighbors_graph(tf_idf_features, n_neighbors=50, mode='distance', include_self=True)\n",
    "preds = ng_spectral_clustering(similarity_matrix=knn_graph, num_clusters=3)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "print(\"Completeness: {} \\n Homogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados obtidos foram melhores do que os obtidos com kmeans, mas os valores das metricas ainda estao baixos.\n",
    "\n",
    "Vamos testar cosine distance como metrica de distancia/similaridade, uma vez que é bastante utilizada ao comparar vetores de frequencia de palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrica de distancia: cosine distance\n",
    "\n",
    "Diversos valores para o numero de vizinhos foram testado n=100 foi o que obteve o melhor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14640]\n"
     ]
    }
   ],
   "source": [
    "knn_graph = kneighbors_graph(tf_idf_features, n_neighbors=200, mode='distance', include_self=True, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnormalized spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.18304064106374418 \n",
      " Homogeinity: 0.12018453196332368\n"
     ]
    }
   ],
   "source": [
    "preds = unnormalized_spectral_clustering(similarity_matrix=knn_graph, num_clusters=3)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "print(\"Completeness: {} \\n Homogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shi Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.17744736102618325 \n",
      " Homogeinity: 0.12821335249492244\n"
     ]
    }
   ],
   "source": [
    "preds = shi_spectral_clustering(similarity_matrix=knn_graph, num_clusters=3)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "print(\"Completeness: {} \\n Homogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ng Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.14522097089203506 \n",
      " Homogeinity: 0.11569449084545855\n"
     ]
    }
   ],
   "source": [
    "knn_graph = kneighbors_graph(tf_idf_features, n_neighbors=50, mode='distance', include_self=True, metric='cosine')\n",
    "preds = ng_spectral_clustering(similarity_matrix=knn_graph, num_clusters=3)\n",
    "completeness = metrics.completeness_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "homogeinity = metrics.homogeneity_score(labels_true=train_ds.airline_sentiment, labels_pred=preds)\n",
    "print(\"Completeness: {} \\n Homogeinity: {}\".format(completeness, homogeinity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected graph\n",
    "\n",
    "Vamos realizar os mesmos testes utilizando um grafo fully connected\n",
    "\n",
    "Importante notar que, apesar de mais simples em termos de hiperparâmetros, o tempo de execução e requisito de memória para esse tipo de grafo é bem maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_graph = metrics.pairwise.pairwise_distances(tf_idf_features.toarray(), metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
